{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1583a2f0-af53-4901-8ad9-41a1dcfb93a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "model_name = 'facebook/nllb-200-distilled-1.3B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c11de42c-3980-4e81-b0eb-5ca5dd3348e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# Prepare the reference and candidate sentences\n",
    "reference = [['this', 'is', 'a', 'test']]\n",
    "candidate = ['this', 'is', 'a', 'test']\n",
    "\n",
    "# Calculate the BLEU score\n",
    "bleu_score = sentence_bleu(reference, candidate)\n",
    "print(\"BLEU score:\", bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a22f63a2-b7df-4773-9cd0-f365228a72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_paragraph(paragraph, chunk_size):\n",
    "    chunks = []\n",
    "    start_index = 0\n",
    "    lists = paragraph.split(' ')\n",
    "    # print(lists)\n",
    "    csize = len(lists)//chunk_size\n",
    "    while(start_index+csize<len(lists)):\n",
    "        chunk = lists[start_index:start_index+csize]\n",
    "        chunks.append(chunk)\n",
    "        start_index += csize\n",
    "    return chunks\n",
    "    \n",
    "def process_chunks(chunks):\n",
    "    phrases = []\n",
    "    for c in chunks:\n",
    "        phrases.append(\" \".join(c))\n",
    "    return phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49c8037f-47aa-4fa5-b958-f48a1fbc736e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a very long paragrpah,', 'detailing every account of what may', 'or may not happen in life.', 'Life as we know it, is', 'not linear but rather karmic and']\n",
      "['This is a', 'very long paragrpah,', 'detailing every account', 'of what may', 'or may not', 'happen in life.', 'Life as we', 'know it, is', 'not linear but', 'rather karmic and']\n",
      "['This is', 'a very', 'long paragrpah,', 'detailing every', 'account of', 'what may', 'or may', 'not happen', 'in life.', 'Life as', 'we know', 'it, is', 'not linear', 'but rather', 'karmic and']\n",
      "['This', 'is', 'a', 'very', 'long', 'paragrpah,', 'detailing', 'every', 'account', 'of', 'what', 'may', 'or', 'may', 'not', 'happen', 'in', 'life.', 'Life', 'as', 'we', 'know', 'it,', 'is', 'not', 'linear', 'but', 'rather', 'karmic', 'and']\n"
     ]
    }
   ],
   "source": [
    "paragraph = 'This is a very long paragrpah, detailing every account of what may or may not happen in life. Life as we know it, is not linear but rather karmic and cyclic.'\n",
    "chunk_sizes = [5, 10, 15, 20]\n",
    "pr_par = []\n",
    "for chunk_size in chunk_sizes:\n",
    "    chunks = break_paragraph(paragraph, chunk_size)\n",
    "    # print(chunks)\n",
    "    processed_paragraph = process_chunks(chunks)\n",
    "    print(processed_paragraph)\n",
    "    pr_par.append(processed_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eae0129f-80b8-4db1-907e-9bab02bd8eb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'translate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate\u001b[49m(source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhin_Deva\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'translate' is not defined"
     ]
    }
   ],
   "source": [
    "test = translate(source, 'hin_Deva')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dbac2b-68d8-4d1d-ae88-17821e1d1f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class translate():\n",
    "  def __init__(self, source, target):\n",
    "    self.source = source\n",
    "    self.target = target\n",
    "    self.pipeline = pipeline('translation', model=model, tokenizer=tokenizer, src_lang=source, tgt_lang=target)\n",
    "\n",
    "  def infer(self, text, max_length=1000):\n",
    "    output = self.pipeline(text, max_length=max_length)\n",
    "    translated_text = output[0]['translation_text']\n",
    "    return translated_text\n",
    "\n",
    "source = 'eng_Latn'\n",
    "# target_1 = 'hin_Deva'\n",
    "# target_2 = 'urd_Arab'\n",
    "# target_3 = 'mar_Deva'\n",
    "# target_4 = 'fra_Latn'\n",
    "# target_5 = 'deu_Latn'\n",
    "\n",
    "target_languages = ['hin_Deva', 'urd_Arab', 'mar_Deva', 'fra_Latn', 'deu_Latn']\n",
    "\n",
    "text = 'This is a very long paragrpah, detailing every account of what may or may not happen in life. Life as we know it, is not linear but rather karmic and cyclic.'\n",
    "\n",
    "\n",
    "\n",
    "# obj1 = translate(source, target_1)\n",
    "# obj2 = translate(source, target_2)\n",
    "# obj3 = translate(source, target_3)\n",
    "# obj4 = translate(source, target_4)\n",
    "# obj5 = translate(source, target_5)\n",
    "\n",
    "class_obj_list = []\n",
    "for i in range(5):\n",
    "  class_obj_list.append(translate(source, target_languages[i]))\n",
    "\n",
    "def make_life_easy(class_obj):\n",
    "  time1 = time.perf_counter()\n",
    "  print(f\"Translated to '{class_obj.target}' Translation is '{class_obj.infer(text)}'\")\n",
    "  print(f\"Inference time = {time.perf_counter() - time1}\")\n",
    "  print()\n",
    "\n",
    "\n",
    "# make_life_easy(obj1)\n",
    "# make_life_easy(obj2)\n",
    "# make_life_easy(obj3)\n",
    "# make_life_easy(obj4)\n",
    "# make_life_easy(obj5)\n",
    "\n",
    "# for i in range(5):\n",
    "#   make_life_easy(class_obj_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633b4dbc-0361-4f5c-a450-693ee82794b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6643772-8b07-46e6-b5ac-77fae18ac98b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.cloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 25\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected source language: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetectedSourceLanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m---> 25\u001b[0m \u001b[43mtranslate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthis is a random\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 7\u001b[0m, in \u001b[0;36mtranslate_text\u001b[1;34m(target, text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranslate_text\u001b[39m(target: \u001b[38;5;28mstr\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Translates text into the target language.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    Target must be an ISO 639-1 language code.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    See https://g.co/cloud/translate/v2/translate-reference#supported_languages\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m translate_v2 \u001b[38;5;28;01mas\u001b[39;00m translate\n\u001b[0;32m      9\u001b[0m     translate_client \u001b[38;5;241m=\u001b[39m translate\u001b[38;5;241m.\u001b[39mClient()\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mbytes\u001b[39m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.cloud'"
     ]
    }
   ],
   "source": [
    "def translate_text(target: str, text: str) -> dict:\n",
    "    \"\"\"Translates text into the target language.\n",
    "\n",
    "    Target must be an ISO 639-1 language code.\n",
    "    See https://g.co/cloud/translate/v2/translate-reference#supported_languages\n",
    "    \"\"\"\n",
    "    from google.cloud import translate_v2 as translate\n",
    "\n",
    "    translate_client = translate.Client()\n",
    "\n",
    "    if isinstance(text, bytes):\n",
    "        text = text.decode(\"utf-8\")\n",
    "\n",
    "    # Text can also be a sequence of strings, in which case this method\n",
    "    # will return a sequence of results for each text.\n",
    "    result = translate_client.translate(text, target_language=target)\n",
    "\n",
    "    print(\"Text: {}\".format(result[\"input\"]))\n",
    "    print(\"Translation: {}\".format(result[\"translatedText\"]))\n",
    "    print(\"Detected source language: {}\".format(result[\"detectedSourceLanguage\"]))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "translate_text('hi', 'this is a random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f0715-118f-4c84-91e7-baa6b4bb8dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ac1aa12-729c-4120-8dda-e77afd7a18eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DoctranTextTranslator\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocuments\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_transformers import DoctranTextTranslator\n",
    "from langchain_core.documents import Document"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
